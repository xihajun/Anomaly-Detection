考试完了做个总结，也希望自己不要忘记这些天辛苦学到的内容！
https://www.zhihu.com/question/23149768/answer/583488480

总结分为几个部分：首先是想说一下这个课对我来说难点是什么，学到了一些什么方法，然后是还有什么不了解的，需要深入了解的，最后就是一些参考书籍以及视频的整理！希望对后人有所帮助！

Anomaly Detection对我来说之前是完全陌生的领域（Dan也这么说，哈哈）虽然我之前有一门课用SPSS，但是几乎都是在学怎么用那个软件，对其中的数学知识几乎没有什么涉及。
这课主要是假设检验方面的内容:Hyperthesis test（不知道有没有拼错），在读了很多优秀的博客之后，愚钝的我终于了解到一点点它的精华。之前一直觉得他是一个所谓的伪科学，因为他的产生就有点奇怪。
先说说难点，对于我来说，理解这个假设检验到底是干嘛的、有什么用是最难的，可能是因为用英语教学，我没有get到老师的很多点，自己在看了很多视频和文字之后才觉得恍然大悟（虽然也不一定全对）。一旦理解了其应用价值，我便有了学习的动力。
假设主要的目的其实很简单，就是根据一些实验数据做一个推断，如果这个实验发生对原来的假设是一个小概率事件，那么我们就拒绝原来的假设，否则就不拒绝，主要好像是在医学方面用处最大，这里就不举这些例子因为自己也不是很懂。通过这个呢，我们就能引入一个叫做p值的东西，（有的老师说p值就是probabilty有的老师却不同意，这里我也不细说），p值我认为就是这个事件极端情况下发生的概率，如果这个概率小于一个值，我就不举具体的值了，就是一个很小的值，由于他表示极端条件下的概率，而且又是一个很小的值，就表示在原来假设下，发生的概率太小了，是不是原来的假设不成立呢？这样就有理由把原来的假设拒绝了！所以就说是拒绝原假设(null hypothesis)，但是并不意味着可以接受你的对立假设(alternative hypothesis)，但如果你对立假设和原假设是一个补集的关系的话，拒绝了原假设也意味着接受了对立假设。
但是小概率事件发生的概率还是有的，如果进行了大量的独立实验，小概率至少发生的一次情况也变大了，于是就需要对这种情况进行讨论引出了p值的校准或者说矫正。总体思想是吧至少发生一次的情况的概率降低到一个很小的水平。但是我目前还没深入理解这个降低的本质对于原来p值的影响是什么，似乎有的更加苛刻，有的又较为温和。
再有一个是combining p-values，这个东西，我之前和p值的校准一直傻傻分不清，感觉他们很相似。现在我感觉，combining p-values是表示对一个整体的实验产生的一大堆p值进行分析，再看看我这个整体考虑的话是否要拒绝原来的假设。就想之前说的小概率在很多独立实验下发生一次的可能性还是比较大的，那么Fisher的方法，就是说把这些p值乘起来作为检验统计量，（可能因为小的数相乘可以把结果叠加的缘故），比如一串p值里面，我只有一个0.01很小，其他都是1，1，1，1，这样他们相乘之后对于总体来说可能就不是很小的一个数了，这样就说只是小概率的事件发生了，总的来说还是不能拒绝原假设的！
我感觉这差不多就是我目前所记得的了！
